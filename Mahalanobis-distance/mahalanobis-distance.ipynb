{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <H1 style=\"color:#e320c2\">Distance de Mahalanobis</H1>\n",
    "        <P>La distance de Mahalanobis est une métrique de distance multivariée efficace qui mesure la distance entre un point et une distribution. C'est une métrique extrêmement utile ayant d'excellentes applications dans la détection d'anomalies multivariées, la classification sur des ensembles de données très déséquilibrés et la classification à une classe. Cet article explique l'intuition et les mathématiques avec des exemples pratiques sur trois cas d'utilisation de l'apprentissage automatique.</P>\n",
    "       </BODY>\n",
    "</HTML>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <H1 style=\"color:#0409A0\">1. Introduction</H1>\n",
    "        <P>La distance de Mahalanobis est une métrique de distance multivariée efficace qui mesure la distance entre un point (vecteur) et une distribution .Il a d'excellentes applications dans la détection d'anomalies multivariées, la classification sur des ensembles de données très déséquilibrés et la classification à une classe et des cas d'utilisation plus inexploités.\n",
    "\n",
    "Compte tenu de ses applications extrêmement utiles, cette métrique est rarement discutée ou utilisée dans les statistiques ou les flux de travail ML. Cet article explique le pourquoi et le quand utiliser la distance de Mahalanobis, puis explique l'intuition et les mathématiques avec des applications utiles.</P>\n",
    "       </BODY>\n",
    "</HTML>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <H1 style=\"color:#0409A0\">2. Quel est le problème avec l'utilisation de la distance euclidienne pour les données multivariées ?</H1>\n",
    "        <P>Commençons par les bases. La distance euclidienne est la distance en ligne droite couramment utilisée entre deux points.\n",
    "\n",
    "Si les deux points sont dans un plan à deux dimensions (ce qui signifie que vous avez deux colonnes numériques (p) et (q)) dans votre ensemble de données), alors la distance euclidienne entre les deux points (p1, q1) et (p2, q2 ) est:</P>\n",
    "        <img alt=\"image\" src=\"img1.PNG\">\n",
    "        <P>Cette formule peut être étendue à autant de dimensions que vous le souhaitez :</P>  \n",
    "        <img alt=\"image\" src=\"img2.PNG\">\n",
    "        <p>Eh bien, la distance euclidienne fonctionnera bien tant que les dimensions sont pondérées de manière égale et indépendantes les unes des autres.\n",
    "\n",
    "Qu'est-ce que je veux dire par là ?</p>\n",
    "        <p>Considérons les tableaux suivants :</p>\n",
    "        <img alt=\"image\" src=\"img4.PNG\">\n",
    "        <P>Les deux tableaux ci-dessus indiquent la « superficie » et le « prix » des mêmes objets. Seules les unités des variables changent.\n",
    "\n",
    "Étant donné que les deux tableaux représentent les mêmes entités, la distance entre deux lignes quelconques, le point A et le point B doit être la même. Mais la distance euclidienne donne une valeur différente même si les distances sont techniquement les mêmes dans l'espace physique.\n",
    "\n",
    "Cela peut être techniquement surmonté en mettant les variables à l'échelle, en calculant le score z (ex : (x - moyen) / std) ou en le faisant varier dans une plage particulière comme entre 0 et 1.\n",
    "\n",
    "Mais il y a un autre inconvénient majeur.\n",
    "\n",
    "Autrement dit, si les dimensions (colonnes de votre jeu de données) sont corrélées les unes aux autres, ce qui est généralement le cas dans les jeux de données du monde réel, la distance euclidienne entre un point et le centre des points (distribution) peut donner des informations peu ou trompeuses à quel point un point est vraiment proche du cluster.</P>\n",
    "         <img alt=\"image\" src=\"img5.PNG\">\n",
    "        <p>L'image ci-dessus (à droite) est un simple nuage de points de deux variables positivement corrélées l'une à l'autre. Autrement dit, à mesure que la valeur d'une variable (axe des x) augmente, la valeur de l'autre variable (axe des y) augmente également.\n",
    "\n",
    "Les deux points ci-dessus sont à égale distance (euclidien) du centre. Mais un seul d'entre eux (bleu) est en réalité plus proche de l'amas, même si, techniquement, la distance euclidienne entre les deux points est égale.\n",
    "        En effet, la distance euclidienne est une distance entre deux points seulement. Il ne tient pas compte de la variation des autres points de l'ensemble de données. Ainsi, il ne peut pas être utilisé pour vraiment juger à quel point un point est réellement proche d'une distribution de points.\n",
    "\n",
    "Ce dont nous avons besoin ici, c'est d'une métrique de distance plus robuste qui soit une représentation précise de la distance entre un point et une distribution.</p>      \n",
    "   </BODY>\n",
    "</HTML>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <H1 style=\"color:#0409A0\">3. Quelle est la distance de Mahalanobis ?</H1>\n",
    "        <p>La distance de Mahalonobis est la distance entre un point et une distribution. Et non entre deux points distincts. C'est effectivement un équivalent multivarié de la distance euclidienne.\n",
    "\n",
    "Il a été introduit par le professeur P. C. Mahalanobis en 1936 et a depuis été utilisé dans diverses applications statistiques. Cependant, il n'est pas si bien connu ou utilisé dans la pratique de l'apprentissage automatique. Eh bien, entrons-y.\n",
    "Donc, d'un point de vue informatique, en quoi la distance de Mahalanobis est-elle différente de la distance euclidienne ?</p>\n",
    "        <p>-Il transforme les colonnes en variables non corrélées</p>\n",
    "        <p>-Mettez les colonnes à l'échelle pour que leur variance soit égale à 1</p>\n",
    "        <p>-Enfin, il calcule la distance euclidienne.</p>\n",
    "<p>Les trois étapes ci-dessus visent à résoudre les problèmes de distance euclidienne dont nous venons de parler. Mais comment?\n",
    "\n",
    "Regardons la formule et essayons de comprendre ses composants. </p>\n",
    "   </BODY>\n",
    "</HTML>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <H1 style=\"color:#0409A0\">4.Les mathématiques et l'intuition derrière Mahalanobis Distance</H1>\n",
    "        <P>La formule pour calculer la distance de Mahalanobis est la suivante :</P>\n",
    "        <img alt=\"image\" src=\"img3.PNG\">\n",
    "        <p>where, \n",
    "            - D^2 est le carré de la distance de Mahalanobis. </p>\n",
    "        <p> - x est le vecteur de l'observation (ligne dans un jeu de données),</p> \n",
    "        <p> - m est le vecteur des valeurs moyennes des variables indépendantes (moyenne de chaque colonne),</p>\n",
    "        <p> - C^(-1) est la matrice de covariance inverse des variables indépendantes.</p>\n",
    "        \n",
    "   </BODY>\n",
    "</HTML>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Prenons le (x – m)^T . C^(-1) terme.\n",
    "\n",
    "(x – m) est essentiellement la distance du vecteur à la moyenne. Nous divisons ensuite cela par la matrice de covariance (ou multiplions par l'inverse de la matrice de covariance).\n",
    "\n",
    "Si vous y réfléchissez, il s'agit essentiellement d'un équivalent multivarié de la normalisation régulière (z = (x – mu)/sigma). C'est-à-dire z = (vecteur x) – (vecteur moyen) / (matrice de covariance).\n",
    "\n",
    "Alors, quel est l'effet de la division par la covariance ?\n",
    "\n",
    "Si les variables de votre ensemble de données sont fortement corrélées, la covariance sera élevée. La division par une grande covariance réduira efficacement la distance.\n",
    "\n",
    "De même, si les X ne sont pas corrélés, alors la covariance n'est pas élevée et la distance n'est pas beaucoup réduite.\n",
    "\n",
    "Donc effectivement, il aborde à la fois les problèmes d'échelle ainsi que la corrélation des variables dont nous avons parlé dans l'introduction.</p>\n",
    "    </body>\n",
    "</html>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "     <p>Alors, comment comprendre la formule ci-dessus ?</p>\n",
    "     <p>Prenons le (x – m)^T . C^(-1) terme.\n",
    "\n",
    "(x – m) est essentiellement la distance du vecteur à la moyenne. Nous divisons ensuite cela par la matrice de covariance (ou multiplions par l'inverse de la matrice de covariance).\n",
    "\n",
    "Si vous y réfléchissez, il s'agit essentiellement d'un équivalent multivarié de la normalisation régulière (z = (x – mu)/sigma). C'est-à-dire z = (vecteur x) – (vecteur moyen) / (matrice de covariance).\n",
    "\n",
    "Alors, quel est l'effet de la division par la covariance ?\n",
    "\n",
    "Si les variables de votre ensemble de données sont fortement corrélées, la covariance sera élevée. La division par une grande covariance réduira efficacement la distance.\n",
    "\n",
    "De même, si les X ne sont pas corrélés, alors la covariance n'est pas élevée et la distance n'est pas beaucoup réduite.\n",
    "\n",
    "Donc effectivement, il aborde à la fois les problèmes d'échelle ainsi que la corrélation des variables dont nous avons parlé dans l'introduction.</p>\n",
    "    </body>\n",
    "</html>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <H1 style=\"color:#0409A0\">5.Comment calculer la distance de Mahalanobis en Python</H1>\n",
    "   </BODY>\n",
    "</HTML>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  price\n",
       "0   0.23   61.5    326\n",
       "1   0.21   59.8    326\n",
       "2   0.23   56.9    327\n",
       "3   0.29   62.4    334\n",
       "4   0.31   63.3    335"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "filepath = 'https://raw.githubusercontent.com/selva86/datasets/master/diamonds.csv'\n",
    "df = pd.read_csv(filepath).iloc[:, [0,4,6]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <p>Écrivons la fonction pour calculer la distance de Mahalanobis.</p>\n",
    "    </BODY>\n",
    "</HTML>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>mahala</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>326</td>\n",
       "      <td>1.709860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>326</td>\n",
       "      <td>3.540097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "      <td>12.715021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>334</td>\n",
       "      <td>1.454469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>335</td>\n",
       "      <td>2.347239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  price     mahala\n",
       "0   0.23   61.5    326   1.709860\n",
       "1   0.21   59.8    326   3.540097\n",
       "2   0.23   56.9    327  12.715021\n",
       "3   0.29   62.4    334   1.454469\n",
       "4   0.31   63.3    335   2.347239"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "def mahalanobis(x=None, data=None, cov=None):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n",
    "    x    : vector or matrix of data with, say, p columns.\n",
    "    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n",
    "    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(data)\n",
    "    if not cov:\n",
    "        cov = np.cov(data.values.T)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return mahal.diagonal()\n",
    "\n",
    "df_x = df[['carat', 'depth', 'price']].head(500)\n",
    "df_x['mahala'] = mahalanobis(x=df_x, data=df[['carat', 'depth', 'price']])\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <h2><b style=\"color:#F17F0C\">Cas d'utilisation 1 : détection des valeurs aberrantes multivariées à l'aide de la distance de Mahalanobis</b></h2>\n",
    "        <p>En supposant que la statistique de test suit une distribution du chi carré avec « n » degrés de liberté, la valeur critique à un niveau de signification de 0,01 et 2 degrés de liberté est calculée comme suit :</p>\n",
    "    </body>\n",
    " </html>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.21034037197618"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeurs critiques pour deux degrés de liberté\n",
    "from scipy.stats import chi2\n",
    "chi2.ppf((1-0.01), df=2)\n",
    "#> 9.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "   <body>\n",
    "       <p>Cela signifie qu'une observation peut être considérée comme extrême si sa distance de Mahalanobis dépasse 9,21.\n",
    "Si vous préférez plutôt les valeurs P pour déterminer si une observation est extrême ou non, les valeurs P peuvent être calculées comme suit :</p>\n",
    "    </body>\n",
    "</html>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>mahala</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "      <td>12.715021</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.86</td>\n",
       "      <td>55.1</td>\n",
       "      <td>2757</td>\n",
       "      <td>23.909643</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.96</td>\n",
       "      <td>66.3</td>\n",
       "      <td>2759</td>\n",
       "      <td>11.781773</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.17</td>\n",
       "      <td>60.2</td>\n",
       "      <td>2774</td>\n",
       "      <td>9.279459</td>\n",
       "      <td>0.009660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.98</td>\n",
       "      <td>67.9</td>\n",
       "      <td>2777</td>\n",
       "      <td>20.086616</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.70</td>\n",
       "      <td>57.2</td>\n",
       "      <td>2782</td>\n",
       "      <td>10.405659</td>\n",
       "      <td>0.005501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.84</td>\n",
       "      <td>55.1</td>\n",
       "      <td>2782</td>\n",
       "      <td>23.548379</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.05</td>\n",
       "      <td>65.8</td>\n",
       "      <td>2789</td>\n",
       "      <td>11.237146</td>\n",
       "      <td>0.003630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1.00</td>\n",
       "      <td>58.2</td>\n",
       "      <td>2795</td>\n",
       "      <td>10.349019</td>\n",
       "      <td>0.005659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1.01</td>\n",
       "      <td>67.4</td>\n",
       "      <td>2797</td>\n",
       "      <td>17.716144</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     carat  depth  price     mahala   p_value\n",
       "2     0.23   56.9    327  12.715021  0.001734\n",
       "91    0.86   55.1   2757  23.909643  0.000006\n",
       "97    0.96   66.3   2759  11.781773  0.002765\n",
       "172   1.17   60.2   2774   9.279459  0.009660\n",
       "204   0.98   67.9   2777  20.086616  0.000043\n",
       "221   0.70   57.2   2782  10.405659  0.005501\n",
       "227   0.84   55.1   2782  23.548379  0.000008\n",
       "255   1.05   65.8   2789  11.237146  0.003630\n",
       "284   1.00   58.2   2795  10.349019  0.005659\n",
       "298   1.01   67.4   2797  17.716144  0.000142"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the P-Values\n",
    "df_x['p_value'] = 1 - chi2.cdf(df_x['mahala'], 2)\n",
    "\n",
    "# Extreme values with a significance level of 0.01\n",
    "df_x.loc[df_x.p_value < 0.01].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Si vous comparez les observations ci-dessus au reste de l'ensemble de données, elles sont clairement extrêmes.</p>\n",
    "    </body>\n",
    " </html>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <h2><b style=\"color:#F17F0C\">Cas d'utilisation 2 : Distance de Mahalanobis pour les problèmes de classification</b></h2>\n",
    "        <p>La distance Mahalanobis peut être utilisée pour des problèmes de classification. Une implémentation naïve d'un classificateur Mahalanobis est codée ci-dessous. L'intuition est qu'une observation se voit attribuer la classe dont elle est la plus proche en fonction de la distance de Mahalanobis.\n",
    "\n",
    "Voyons un exemple d'implémentation sur le jeu de données BreastCancer, où l'objectif est de déterminer si une tumeur est bénigne ou maligne.</p>\n",
    "    </body>\n",
    " </html>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cl.thickness  Cell.size  Marg.adhesion  Epith.c.size  Bare.nuclei  \\\n",
       "0             5          1              1             2          1.0   \n",
       "1             5          4              5             7         10.0   \n",
       "2             3          1              1             2          2.0   \n",
       "3             6          8              1             3          4.0   \n",
       "4             4          1              3             2          1.0   \n",
       "\n",
       "   Bl.cromatin  Normal.nucleoli  Mitoses  Class  \n",
       "0            3                1        1      0  \n",
       "1            3                2        1      0  \n",
       "2            3                1        1      0  \n",
       "3            3                7        1      0  \n",
       "4            3                1        1      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BreastCancer.csv', \n",
    "                 usecols=['Cl.thickness', 'Cell.size', 'Marg.adhesion', \n",
    "                          'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', \n",
    "                          'Mitoses', 'Class'])\n",
    "\n",
    "df.dropna(inplace=True)  # drop missing values.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Séparons l'ensemble de données dans un rapport 70:30 en tant qu'entraînement et test. Et l'ensemble de données d'apprentissage est divisé en groupes homogènes de classes 'pos'(1) et 'neg'(0). Pour prédire la classe de l'ensemble de données de test, nous mesurons les distances de Mahalanobis entre une observation donnée (ligne) et les ensembles de données positifs (xtrain_pos) et négatifs (xtrain_neg).\n",
    "\n",
    "Ensuite, cette observation est attribuée à la classe en fonction du groupe dont elle est la plus proche.</p>\n",
    "    </body>\n",
    " </html>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=.3, random_state=100)\n",
    "\n",
    "# Split the training data as pos and neg\n",
    "xtrain_pos = xtrain.loc[ytrain == 1, :]\n",
    "xtrain_neg = xtrain.loc[ytrain == 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Construisons le MahalanobiBinaryClassifier. Pour ce faire, vous devez définir les méthodes predict_proba() et predict(). Ce classificateur ne nécessite pas de méthode fit() (entraînement) distincte.</p>\n",
    "    </body>\n",
    " </html>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred  true\n",
      "0     0     0\n",
      "1     1     1\n",
      "2     0     0\n",
      "3     0     0\n",
      "4     0     0\n"
     ]
    }
   ],
   "source": [
    "class MahalanobisBinaryClassifier():\n",
    "    def __init__(self, xtrain, ytrain):\n",
    "        self.xtrain_pos = xtrain.loc[ytrain == 1, :]\n",
    "        self.xtrain_neg = xtrain.loc[ytrain == 0, :]\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        pos_neg_dists = [(p,n) for p, n in zip(mahalanobis(xtest, self.xtrain_pos), mahalanobis(xtest, self.xtrain_neg))]\n",
    "        return np.array([(1-n/(p+n), 1-p/(p+n)) for p,n in pos_neg_dists])\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([np.argmax(row) for row in self.predict_proba(xtest)])\n",
    "\n",
    "\n",
    "clf = MahalanobisBinaryClassifier(xtrain, ytrain)        \n",
    "pred_probs = clf.predict_proba(xtest)\n",
    "pred_class = clf.predict(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "pred_actuals = pd.DataFrame([(pred, act) for pred, act in zip(pred_class, ytest)], columns=['pred', 'true'])\n",
    "print(pred_actuals[:5])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Voyons comment le classificateur a fonctionné sur l'ensemble de données de test.</p>\n",
    "    </body>\n",
    " </html>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  0.990974358974359\n",
      "\n",
      "Confusion Matrix: \n",
      " [[113  17]\n",
      " [  0  75]]\n",
      "\n",
      "Accuracy Score:  0.9170731707317074\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93       130\n",
      "           1       0.82      1.00      0.90        75\n",
      "\n",
      "    accuracy                           0.92       205\n",
      "   macro avg       0.91      0.93      0.91       205\n",
      "weighted avg       0.93      0.92      0.92       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "scores = np.array(pred_probs)[:, 1]\n",
    "print('AUROC: ', roc_auc_score(truth, scores))\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>La distance de Mahalanobis à elle seule peut contribuer à cette précision (92%).</p>\n",
    "    </body>\n",
    " </html>   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <h2><b style=\"color:#F17F0C\">Cas d'utilisation 3 : Classification à une classe</b></h2>\n",
    "        <p>La classification à une classe est un type d'algorithme dans lequel l'ensemble de données d'apprentissage contient des observations appartenant à une seule classe.\n",
    "\n",
    "Avec seulement cette information connue, l'objectif est de déterminer si une observation donnée dans un nouvel ensemble de données (ou de test) appartient à cette classe.\n",
    "\n",
    "Vous pourriez vous demander quand une telle situation se produirait. Eh bien, c'est un problème assez courant en Data Science.\n",
    "\n",
    "Par exemple, considérons la situation suivante : vous disposez d'un vaste ensemble de données contenant des millions d'enregistrements qui ne sont PAS encore classés en 1 et en 0. Mais vous avez également avec vous un petit échantillon de données contenant uniquement des enregistrements positifs. En apprenant les informations de cet exemple de jeu de données, vous souhaitez classer tous les enregistrements du grand jeu de données en 1 et en 0.\n",
    "\n",
    "Sur la base des informations de l'ensemble de données de l'échantillon, il est possible de dire si un échantillon donné est un 1 ou un 0 en ne visualisant que les 1 (et en n'ayant aucune connaissance des 0).\n",
    "\n",
    "Cela peut être fait en utilisant la distance de Mahalanobis.\n",
    "\n",
    "Essayons ceci sur l'ensemble de données BreastCancer, mais cette fois-ci, nous ne considérerons que les observations malignes (colonne de classe=1) dans les données d'entraînement.</p>\n",
    "    </body>\n",
    " </html> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BreastCancer.csv', \n",
    "                 usecols=['Cl.thickness', 'Cell.size', 'Marg.adhesion', \n",
    "                          'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', \n",
    "                          'Mitoses', 'Class'])\n",
    "\n",
    "df.dropna(inplace=True)  # drop missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Diviser 50 % de l'ensemble de données en entraînement et test. Seuls les 1 sont conservés dans les données d'entraînement.</p>\n",
    "    </body>\n",
    " </html>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=.5, random_state=100)\n",
    "\n",
    "# Split the training data as pos and neg\n",
    "xtrain_pos = xtrain.loc[ytrain == 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Construisons le MahalanobisOneClassClassifier et obtenons la distance mahalanobis de chaque point de données en x à partir de l'ensemble d'apprentissage (xtrain_pos).</p>\n",
    "    </body>\n",
    " </html>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value is:  14.067140449340169\n",
      "       mahal  true_class\n",
      "0  13.104716           0\n",
      "1  14.408570           1\n",
      "2  14.932236           0\n",
      "3  14.588622           0\n",
      "4  15.471064           0\n"
     ]
    }
   ],
   "source": [
    "class MahalanobisOneclassClassifier():\n",
    "    def __init__(self, xtrain, significance_level=0.01):\n",
    "        self.xtrain = xtrain\n",
    "        self.critical_value = chi2.ppf((1-significance_level), df=xtrain.shape[1]-1)\n",
    "        print('Critical value is: ', self.critical_value)\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        mahalanobis_dist = mahalanobis(xtest, self.xtrain)\n",
    "        self.pvalues = 1 - chi2.cdf(mahalanobis_dist, 2)\n",
    "        return mahalanobis_dist\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([int(i) for i in self.predict_proba(xtest) > self.critical_value])\n",
    "\n",
    "clf = MahalanobisOneclassClassifier(xtrain_pos, significance_level=0.05)\n",
    "mahalanobis_dist = clf.predict_proba(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "mdist_actuals = pd.DataFrame([(m, act) for m, act in zip(mahalanobis_dist, ytest)], columns=['mahal', 'true_class'])\n",
    "print(mdist_actuals[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Nous avons la distance de Mahalanobis et la classe réelle de chaque observation.\n",
    "\n",
    "Je m'attendrais à ce que ces observations avec une faible distance de Mahalanobis soient de 1.\n",
    "\n",
    "Donc, je trie les mdist_actuals par distance de Mahalanobis et le quantile coupe les lignes en 10 groupes de taille égale. Les observations dans les quantiles supérieurs devraient avoir plus de 1 par rapport à celles du bas. Voyons.</p>\n",
    "    </body>\n",
    " </html>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          avg_mahaldist  sum_of_trueclass\n",
      "quantile                                 \n",
      "1              3.765496                33\n",
      "2              6.511026                32\n",
      "3              9.272944                30\n",
      "4             12.209504                20\n",
      "5             14.455050                 4\n",
      "6             15.684493                 4\n",
      "7             17.368633                 3\n",
      "8             18.840714                 1\n",
      "9             21.533159                 2\n",
      "10            23.524055                 1\n"
     ]
    }
   ],
   "source": [
    "# quantile cut in 10 pieces\n",
    "mdist_actuals['quantile'] = pd.qcut(mdist_actuals['mahal'], \n",
    "                                    q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "                                    labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# sort by mahalanobis distance\n",
    "mdist_actuals.sort_values('mahal', inplace=True)\n",
    "perc_truths = mdist_actuals.groupby('quantile').agg({'mahal': np.mean, 'true_class': np.sum}).rename(columns={'mahal':'avg_mahaldist', 'true_class':'sum_of_trueclass'})\n",
    "print(perc_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Si vous remarquez ci-dessus, près de 90 % des 1 (cas malins) se situent dans les premiers 40 % de la distance de Mahalanobis. Incidemment, tous ces éléments sont inférieurs à la valeur critique pf 14,05. Alors, prenons la valeur critique comme seuil et marquons ces observations avec une distance de Mahalanobis inférieure au seuil comme positives.</p>\n",
    "    </body>\n",
    " </html>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix: \n",
      " [[183  29]\n",
      " [ 15 115]]\n",
      "\n",
      "Accuracy Score:  0.8713450292397661\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       212\n",
      "           1       0.80      0.88      0.84       130\n",
      "\n",
      "    accuracy                           0.87       342\n",
      "   macro avg       0.86      0.87      0.87       342\n",
      "weighted avg       0.88      0.87      0.87       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Positive if mahalanobis \n",
    "pred_actuals = pd.DataFrame([(int(p), y) for y, p in zip(ytest, clf.predict_proba(xtest) < clf.critical_value)], columns=['pred', 'true'])\n",
    "\n",
    "# Accuracy Metrics\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <p>Ainsi, sans la connaissance de la classe bénigne, nous sommes en mesure de prédire avec précision la classe de 87 % des observations</p>\n",
    "    </body>\n",
    " </html> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HTML>\n",
    "    <BODY>\n",
    "        <H1 style=\"color:#0409A0\"> Conclusion</H1>\n",
    "        <P>La distance de Mahalanobis est une métrique de distance multivariée efficace qui mesure la distance entre un point (vecteur) et une distribution .Il a d'excellentes applications dans la détection d'anomalies multivariées, la classification sur des ensembles de données très déséquilibrés et la classification à une classe et des cas d'utilisation plus inexploités.\n",
    "\n",
    "Compte tenu de ses applications extrêmement utiles, cette métrique est rarement discutée ou utilisée dans les statistiques ou les flux de travail ML. Cet article explique le pourquoi et le quand utiliser la distance de Mahalanobis, puis explique l'intuition et les mathématiques avec des applications utiles.</P>\n",
    "    </BODY>\n",
    "</HTML>    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
